# ğŸ¬ Video Action Localization App
Video Action Localization App is a Streamlit-powered web interface that processes video input to detect and localize actions across frames using spatio-temporal deep learning models. It leverages MMAction2â€™s SlowFast-ACRN model for action recognition and Faster R-CNN for spatial localization.

A complete, Colab-ready solution for spatio-temporal action detection in videos, featuring:

âœ… SlowFast-ACRN for action recognition
âœ… Faster R-CNN for human/object detection
âœ… Streamlit interface for interactivity
âœ… Google Colab backend for GPU-powered inference

## ğŸš€ Quick Start
âœ… Prerequisites
- A Google Colab account
- GPU runtime enabled in Colab (Runtime > Change runtime type > GPU)
- A free Ngrok account
- Your personal Ngrok Auth Token

## âœ¨ Features
- ğŸ“¤ Upload .mp4, .avi, or .mov video files
- ğŸ§  Perform frame-wise action localization with SlowFast-ACRN
- ğŸ“¥ Download annotated output video with bounding boxes and action labels

## ğŸ§  Model Architecture
Component	Description
Backbone	SlowFast Network with ACRN Head
Detector	Faster R-CNN (ResNet-50-FPN)
Trained On	Kinetics-400 Dataset

## ğŸ› ï¸ Usage
This app is designed to run entirely in Google Colab, using GPU resources for efficient inference, while Streamlit provides the user interface.
- Run the notebook sequentially from top to bottom
- You may be prompted to restart runtime after dependency installations
- Once Ngrok tunnel is active, you'll get a public URL to access your Streamlit app

## ğŸ“ Project Structure

â”œâ”€â”€ Action_Localization.ipynb         # ğŸš€ Main Colab notebook for setup & execution
â”œâ”€â”€ app.py                            # ğŸ’» Streamlit app logic
â”œâ”€â”€ checkpoints/                      # ğŸ§  Model weight files
â”‚   â”œâ”€â”€ slowfast-acrn.pth             #    - Action recognition weights
â”‚   â””â”€â”€ faster_rcnn.pth              #    - Object detection weights
â”œâ”€â”€ mmaction2/                        # ğŸ“¦ MMAction2 framework (cloned repo)
â”‚   â”œâ”€â”€ configs/                      #    - Model configuration files
â”‚   â”œâ”€â”€ demo/                         #    - Sample media for testing
â””â”€â”€ requirements.txt                  # ğŸ“Œ Python dependencies

[Google colab](https://colab.research.google.com/drive/1_5k5CNtlGTmzqxFgkXAll-VXdB4l4KkJ#scrollTo=Uc_ZquyyK_Jk) 

ğŸ‘¤ Author
Ibrahim Mustapha
Mechatronics Engineering Student | Computer Vision & AI Enthusiast
ğŸ”— [GitHub](@ibraztech2)
ğŸ”— [linkedin](https://www.linkedin.com/in/ibraztech)
ğŸ“§ [Email](mustaphaibraz9@gmail.com)

